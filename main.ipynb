{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYs4miY4MIDG"
      },
      "outputs": [],
      "source": [
        "pip install langchain langchain_community unstructured langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters==0.2.2 langchain-huggingface==0.0.3 unstructured==0.15.0 unstructured[pdf]==0.15.0 nltk==3.8.1"
      ],
      "metadata": {
        "id": "jAUYK2yFNrtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet unstructured"
      ],
      "metadata": {
        "id": "5-6qDrmfW9nz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('groqkey')\n",
        "\n",
        "\n",
        "def process_url(url):\n",
        "    \"\"\"\n",
        "    Process the URL: load documents, split text, and create vector store.\n",
        "    \"\"\"\n",
        "    print(f\"Loading data from {url}...\")\n",
        "    loader = WebBaseLoader(url)\n",
        "    data = loader.load()\n",
        "\n",
        "    if not data:\n",
        "        print(f\"Failed to load data from {url}\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        separators=['\\n\\n', '\\n', '.', ','],\n",
        "        chunk_size=1000\n",
        "    )\n",
        "    print(\"Splitting text into chunks...\")\n",
        "    docs = text_splitter.split_documents(data)\n",
        "\n",
        "    embedding = HuggingFaceEmbeddings()\n",
        "\n",
        "    vectorstore = Chroma.from_documents(docs, embedding)\n",
        "    print(\"Data indexed and vectorstore created.\")\n",
        "    time.sleep(2)\n",
        "    return vectorstore\n",
        "\n",
        "def query_vectorstore(query, vectorstore):\n",
        "    \"\"\"\n",
        "    Query the vectorstore and get the answer.\n",
        "    \"\"\"\n",
        "    llm = ChatGroq(temperature=0.9)\n",
        "    chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "    result = chain.invoke({\"question\": query})\n",
        "    return result\n",
        "\n",
        "def main():\n",
        "    url = input(\"Please enter the URL to process: \").strip()\n",
        "\n",
        "    if url:\n",
        "        process_urls_flag = input(f\"Do you want to process the URL: {url}? (yes/no): \").strip().lower()\n",
        "        if process_urls_flag == \"yes\":\n",
        "            vectorstore = process_url(url)\n",
        "            if vectorstore:\n",
        "                print(\"Processing completed. FAISS index created.\")\n",
        "            else:\n",
        "                print(f\"Failed to process {url}.\")\n",
        "                return\n",
        "        else:\n",
        "            print(\"Skipping URL processing.\")\n",
        "            return\n",
        "\n",
        "        while True:\n",
        "            query = input(\"Please enter your question (or type 'exit' to quit): \").strip()\n",
        "            if query.lower() == 'exit':\n",
        "                print(\"Exiting...\")\n",
        "                break\n",
        "            if query:\n",
        "                result = query_vectorstore(query, vectorstore)\n",
        "                if result:\n",
        "                    print(\"\\nAnswer:\")\n",
        "                    print(result[\"answer\"])\n",
        "                else:\n",
        "                    print(\"No answer found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VWQ2X8M_Nlf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96493088-a98e-4c07-8e37-13d5d9ff5fad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the URL to process: http://www.stanford.edu/\n",
            "Do you want to process the URL: http://www.stanford.edu/? (yes/no): yes\n",
            "Loading data from http://www.stanford.edu/...\n",
            "Splitting text into chunks...\n",
            "Data indexed and vectorstore created.\n",
            "Processing completed. FAISS index created.\n",
            "Please enter your question (or type 'exit' to quit): what is in the website\n",
            "\n",
            "Answer:\n",
            "The website StanfordUniversity contains information about Stanford University, including sections about academics, health care services, online learning, admission, applying, visiting, giving, careers, and faculty positions. It also provides information on student life, with details on housing, dining, student organizations, recreation and wellness facilities, arts and culture, and athletics.\n",
            "\n",
            "\n",
            "Please enter your question (or type 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlhj5mbKSH7d",
        "outputId": "36bfe1ce-00fd-4f02-c440-cac48ce251a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "GROQ_API_KEY = userdata.get('groqkey')\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "\n",
        "pdf_path = \"/content/a.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=500\n",
        ")\n",
        "\n",
        "text_chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "embedding = HuggingFaceEmbeddings()\n",
        "\n",
        "persist_directory = \"doc_db\"\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=text_chunks,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Hello! I can help you answer questions from the PDF. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        query = input(\"\\nYour question: \").strip()\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        response = qa_chain.invoke({\"query\": query})\n",
        "        answer = response.get(\"result\", \"Sorry, I couldn't find an answer.\")\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uontv4l_N52o",
        "outputId": "8d7d8ed9-56a2-4713-e672-5efe6ab1001c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I can help you answer questions from the PDF. Type 'exit' to quit.\n",
            "\n",
            "Your question: what is the us gdp of manufacturing in 2011\n",
            "\n",
            "Answer: According to the table, the US GDP of manufacturing in 2011 is 5581942 million dollars.\n",
            "\n",
            "Your question: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}